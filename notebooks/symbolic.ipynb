{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8341afac",
   "metadata": {},
   "source": [
    "# Inicialização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45be223a",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas e funções de auxílio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3985c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "def parse_xml_to_df(xml_root):\n",
    "    # Cria um dataframe vazio em que as linhas serão concatenadas.\n",
    "    df = pd.DataFrame(columns=['similarity', 't', 'h'])\n",
    "    # Para cada par na root.\n",
    "    for pair in xml_root:\n",
    "        # Recupera o valor de t.\n",
    "        t = pair[0].text\n",
    "        # Recupera o valor de h.\n",
    "        h = pair[1].text\n",
    "        # Recupera o valor da variável target.\n",
    "        is_entailment = pair.attrib['entailment'] == 'Entailment'\n",
    "        # Recupera o valor de similaridade atribuído.\n",
    "        similarity = float(pair.attrib['similarity'])\n",
    "        # Constroi a nova linha.\n",
    "        new_line = pd.DataFrame([{'t': t, 'h': h, 'similarity': similarity, 'is_entailment': is_entailment}])\n",
    "        # Adiciona ao dataframe.\n",
    "        df = pd.concat([df, new_line], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_classification_results(y_train, y_train_pred, y_dev, y_dev_pred, y_test, y_test_pred):\n",
    "    # Cria um dataframe com todos o resultado de todas as métricas.\n",
    "    return pd.DataFrame({\n",
    "        'type':['train', 'dev', 'test'],\n",
    "        \n",
    "        'f1': [f1_score(y_train, y_train_pred), \n",
    "               f1_score(y_dev, y_dev_pred), \n",
    "               f1_score(y_test, y_test_pred)],\n",
    "\n",
    "        'precision': [precision_score(y_train, y_train_pred), \n",
    "                      precision_score(y_dev, y_dev_pred), \n",
    "                      precision_score(y_test, y_test_pred)],\n",
    "\n",
    "        'recall': [recall_score(y_train, y_train_pred), \n",
    "                      recall_score(y_dev, y_dev_pred), \n",
    "                      recall_score(y_test, y_test_pred)],\n",
    "\n",
    "        'accuracy': [accuracy_score(y_train, y_train_pred), \n",
    "                     accuracy_score(y_dev, y_dev_pred), \n",
    "                     accuracy_score(y_test, y_test_pred)],\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "affb645f",
   "metadata": {},
   "source": [
    "## Carregando conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c027b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera o arquivo de entrada de treinamento.\n",
    "train_xml_root = et.parse('../data/assin2-train.xml').getroot()\n",
    "# Cria o dataframe de treinamento.\n",
    "df_train = parse_xml_to_df(train_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "dev_xml_root = et.parse('../data/assin2-dev.xml').getroot()\n",
    "# Cria o dataframe de validação.\n",
    "df_dev = parse_xml_to_df(dev_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "test_xml_root = et.parse('../data/assin2-test.xml').getroot()\n",
    "df_test = parse_xml_to_df(test_xml_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e341738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 4)\n",
      "Shape de validação: (500, 4)\n",
      "Shape de teste: (2448, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape de treinamento:', df_train.shape)\n",
    "print('Shape de validação:', df_dev.shape)\n",
    "print('Shape de teste:', df_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31099cfc-6c2e-4273-8afe-ae2e170c0314",
   "metadata": {},
   "source": [
    "## Limpando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76e94f5-9450-4402-9462-cf679838921a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unidecode \n",
    "\n",
    "def clean_string(x):\n",
    "    return unidecode.unidecode(x.lower())\n",
    "\n",
    "# Removendo acentos para normalizar as palavras no conjunto de treinameto.\n",
    "df_train['t'] = df_train['t'].apply(clean_string)\n",
    "df_train['h'] = df_train['h'].apply(clean_string)\n",
    "\n",
    "# Removendo acentos para normalizar as palavras no conjunto de validação.\n",
    "df_dev['t'] = df_dev['t'].apply(clean_string)\n",
    "df_dev['h'] = df_dev['h'].apply(clean_string)\n",
    "\n",
    "# Removendo acentos para normalizar as palavras no conjunto de teste.\n",
    "df_test['t'] = df_test['t'].apply(clean_string)\n",
    "df_test['h'] = df_test['h'].apply(clean_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdbbc9e5",
   "metadata": {},
   "source": [
    "# Aplicando Abordagem Simbólica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5721a322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Abordagem baseada em 3 regras:\n",
    "# Para classificar o par de sentenças como A acarreta B: \n",
    "#   1 - o tamanho da sentença B deve ser menor que o da sentença A\n",
    "#   2 - A taxa de similaridade entre as sentenças deve ser maior que 50%\n",
    "#   3 - A palavra \"não\" deve estar ausente ou presente em ambas as frases, ou presente somente na sentença B\n",
    "def symbolic_approach(df_data):\n",
    "    predictions = []\n",
    "\n",
    "    for index in df_data.index:\n",
    "        # Transformando frases em listas de palavras   \n",
    "        sentence_A = df_data['t'][index].split()\n",
    "        sentence_B = df_data['h'][index].split()\n",
    "\n",
    "        # Criando lista com palavras em comum entre as frases\n",
    "        aux = copy.deepcopy(sentence_B)\n",
    "        common_words = []\n",
    "        for word in sentence_A:\n",
    "            if word in aux:\n",
    "                common_words.append(word)\n",
    "                aux.remove(word)\n",
    "\n",
    "        # Aplicando regras\n",
    "        if len(sentence_B) <= len(sentence_A) and len(common_words)/len(sentence_B) > 0.5:\n",
    "            prediction = True\n",
    "        else:\n",
    "            prediction = False\n",
    "        if \"nao\" in sentence_A and \"nao\" not in sentence_B:\n",
    "            prediction = False\n",
    "\n",
    "        # Debug print\n",
    "        #print(sentence_A, \"\\n\", sentence_B, \"\\n\", common_words, \"\\n\", len(common_words)/len(sentence_B), prediction, \"\\n\")\n",
    "        \n",
    "        # Gerando lista de previsões\n",
    "        predictions.append(prediction) \n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Aplicando as regras para gerar predições\n",
    "y_train_pred = symbolic_approach(df_train)\n",
    "y_dev_pred = symbolic_approach(df_dev)\n",
    "y_test_pred = symbolic_approach(df_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57f903a2",
   "metadata": {},
   "source": [
    "# Calculando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc0a469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.698807</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.666769</td>\n",
       "      <td>0.712615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>0.713693</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0.688765</td>\n",
       "      <td>0.727934</td>\n",
       "      <td>0.653595</td>\n",
       "      <td>0.704657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type        f1  precision    recall  accuracy\n",
       "0  train  0.698807   0.734079  0.666769  0.712615\n",
       "1    dev  0.713693   0.741379  0.688000  0.724000\n",
       "2   test  0.688765   0.727934  0.653595  0.704657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transforma os dados da anotação no formato de vetor binário \n",
    "y_train = df_train['is_entailment'].astype(int)\n",
    "y_dev = df_dev['is_entailment'].astype(int)\n",
    "y_test = df_test['is_entailment'].astype(int)\n",
    "\n",
    "# Transforma os dados da predição no formato de vetor binário \n",
    "y_train_pred = np.array(y_train_pred).astype(int)\n",
    "y_dev_pred = np.array(y_dev_pred).astype(int)\n",
    "y_test_pred = np.array(y_test_pred).astype(int)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "df_symbolic_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(df_symbolic_approach_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
