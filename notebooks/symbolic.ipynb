{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8341afac",
   "metadata": {},
   "source": [
    "# Inicialização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45be223a",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas e funções de auxílio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3985c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "def parse_xml_to_df(xml_root):\n",
    "    # Cria um dataframe vazio em que as linhas serão concatenadas.\n",
    "    df = pd.DataFrame(columns=['similarity', 't', 'h'])\n",
    "    # Para cada par na root.\n",
    "    for pair in xml_root:\n",
    "        # Recupera o valor de t.\n",
    "        t = pair[0].text\n",
    "        # Recupera o valor de h.\n",
    "        h = pair[1].text\n",
    "        # Recupera o valor da variável target.\n",
    "        is_entailment = pair.attrib['entailment'] == 'Entailment'\n",
    "        # Recupera o valor de similaridade atribuído.\n",
    "        similarity = float(pair.attrib['similarity'])\n",
    "        # Constroi a nova linha.\n",
    "        new_line = pd.DataFrame([{'t': t, 'h': h, 'similarity': similarity, 'is_entailment': is_entailment}])\n",
    "        # Adiciona ao dataframe.\n",
    "        df = pd.concat([df, new_line], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_classification_results(y_train, y_train_pred, y_dev, y_dev_pred, y_test, y_test_pred):\n",
    "    # Cria um dataframe com todos o resultado de todas as métricas.\n",
    "    return pd.DataFrame({\n",
    "        'type':['train', 'dev', 'test'],\n",
    "        \n",
    "        'f1': [f1_score(y_train, y_train_pred), \n",
    "               f1_score(y_dev, y_dev_pred), \n",
    "               f1_score(y_test, y_test_pred)],\n",
    "\n",
    "        'precision': [precision_score(y_train, y_train_pred), \n",
    "                      precision_score(y_dev, y_dev_pred), \n",
    "                      precision_score(y_test, y_test_pred)],\n",
    "\n",
    "        'recall': [recall_score(y_train, y_train_pred), \n",
    "                      recall_score(y_dev, y_dev_pred), \n",
    "                      recall_score(y_test, y_test_pred)],\n",
    "\n",
    "        'accuracy': [accuracy_score(y_train, y_train_pred), \n",
    "                     accuracy_score(y_dev, y_dev_pred), \n",
    "                     accuracy_score(y_test, y_test_pred)],\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "affb645f",
   "metadata": {},
   "source": [
    "## Carregando conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c027b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera o arquivo de entrada de treinamento.\n",
    "train_xml_root = et.parse('../data/assin2-train.xml').getroot()\n",
    "# Cria o dataframe de treinamento.\n",
    "df_train = parse_xml_to_df(train_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "dev_xml_root = et.parse('../data/assin2-dev.xml').getroot()\n",
    "# Cria o dataframe de validação.\n",
    "df_dev = parse_xml_to_df(dev_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "test_xml_root = et.parse('../data/assin2-test.xml').getroot()\n",
    "df_test = parse_xml_to_df(test_xml_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e341738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 4)\n",
      "Shape de validação: (500, 4)\n",
      "Shape de teste: (2448, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape de treinamento:', df_train.shape)\n",
    "print('Shape de validação:', df_dev.shape)\n",
    "print('Shape de teste:', df_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31099cfc-6c2e-4273-8afe-ae2e170c0314",
   "metadata": {},
   "source": [
    "## Limpando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76e94f5-9450-4402-9462-cf679838921a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unidecode \n",
    "\n",
    "def clean_string(x):\n",
    "    return unidecode.unidecode(x.lower())\n",
    "\n",
    "# Removendo acentos para normalizar as palavras no conjunto de treinameto.\n",
    "df_train['t'] = df_train['t'].apply(clean_string)\n",
    "df_train['h'] = df_train['h'].apply(clean_string)\n",
    "\n",
    "# Removendo acentos para normalizar as palavras no conjunto de validação.\n",
    "df_dev['t'] = df_dev['t'].apply(clean_string)\n",
    "df_dev['h'] = df_dev['h'].apply(clean_string)\n",
    "\n",
    "# Removendo acentos para normalizar as palavras no conjunto de teste.\n",
    "df_test['t'] = df_test['t'].apply(clean_string)\n",
    "df_test['h'] = df_test['h'].apply(clean_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdbbc9e5",
   "metadata": {},
   "source": [
    "# Aplicando Abordagem Simbólica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5721a322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A abordagem simbólica utilizada leva em consideração critérios teóricos para a diferenciação entre pares de sentenças com e sem inferências\n",
    "# Um conjunto de regras é formado para definir se a sentença A acarreta a sentença B\n",
    "# Considerando que sentenças específicas como \"Um cachorro anda rapidamente pela areia da praia\" podem acarretar sentenças mais gerais como \"Um cachorro anda pela praia\", mas não o contrário, considera-se que a sentença A deve ser maior ou igual à B\n",
    "# Regra 1 de acarretamento: A sentença B deve ser menor ou igual à sentença A em tamanho para que B seja acarretada por A\n",
    "# Regra 2 de acarretamento: As sentenças devem ser significativamente parecidas - verifica-se se o número de palavras em comum dividido pelo tamanho da sentença B é maior que 50%\n",
    "# Se ambas as regras forem verdade, a sentença B é classificada como acarretada pela A\n",
    "# Por fim, se a sentença A contiver o termo \"não\" e a sentença B não, considera-se que não há relação de inferência entre as sentenças\n",
    "def symbolic_approach(df_data):\n",
    "    predictions = []\n",
    "\n",
    "    for index in df_data.index:   \n",
    "        sentence_A = df_data['t'][index].split()\n",
    "        sentence_B = df_data['h'][index].split()\n",
    "        common_words = [word for word in sentence_A if word in sentence_B]\n",
    "        \n",
    "        if len(sentence_B) <= len(sentence_A) and len(common_words)/len(sentence_B) > 0.5:\n",
    "            prediction = True\n",
    "        else:\n",
    "            prediction = False\n",
    "        if \"nao\" in sentence_A and \"nao\" not in sentence_B:\n",
    "            prediction = False\n",
    "\n",
    "        predictions.append(prediction) \n",
    "\n",
    "    return predictions\n",
    "\n",
    "y_train_pred = symbolic_approach(df_train)\n",
    "y_dev_pred = symbolic_approach(df_dev)\n",
    "y_test_pred = symbolic_approach(df_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57f903a2",
   "metadata": {},
   "source": [
    "# Calculando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc0a469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.695185</td>\n",
       "      <td>0.713776</td>\n",
       "      <td>0.677538</td>\n",
       "      <td>0.702923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>0.716904</td>\n",
       "      <td>0.730290</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0.685978</td>\n",
       "      <td>0.705527</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type        f1  precision    recall  accuracy\n",
       "0  train  0.695185   0.713776  0.677538  0.702923\n",
       "1    dev  0.716904   0.730290  0.704000  0.722000\n",
       "2   test  0.685978   0.705527  0.667484  0.694444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transforma os dados da anotação no formato de vetor binário (0 para não acarretamento, 1 para acarretamento)\n",
    "y_train = df_train['is_entailment'].astype(int)\n",
    "y_dev = df_dev['is_entailment'].astype(int)\n",
    "y_test = df_test['is_entailment'].astype(int)\n",
    "\n",
    "y_train_pred = np.array(y_train_pred).astype(int)\n",
    "y_dev_pred = np.array(y_dev_pred).astype(int)\n",
    "y_test_pred = np.array(y_test_pred).astype(int)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "df_symbolic_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(df_symbolic_approach_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
