{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8341afac",
   "metadata": {},
   "source": [
    "# Inicialização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be223a",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas e funções de auxílio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3985c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "\n",
    "def parse_xml_to_df(xml_root):\n",
    "    # Cria um dataframe vazio em que as linhas serão concatenadas.\n",
    "    df = pd.DataFrame(columns=['similarity', 't', 'h'])\n",
    "    # Para cada par na root.\n",
    "    for pair in xml_root:\n",
    "        # Recupera o valor de t.\n",
    "        t = pair[0].text\n",
    "        # Recupera o valor de h.\n",
    "        h = pair[1].text\n",
    "        # Recupera o valor da variável target.\n",
    "        is_entailment = pair.attrib['entailment'] == 'Entailment'\n",
    "        # Recupera o valor de similaridade atribuído.\n",
    "        similarity = float(pair.attrib['similarity'])\n",
    "        # Constroi a nova linha.\n",
    "        new_line = pd.DataFrame([{'t': t, 'h': h, 'similarity': similarity, 'is_entailment': is_entailment}])\n",
    "        # Adiciona ao dataframe.\n",
    "        df = pd.concat([df, new_line], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "    \n",
    "class GenericEstimator(BaseEstimator):\n",
    "    # Classificador genérico para usar o gridsearch com múltiplos algoritmos.\n",
    "    def fit(self): pass\n",
    "    \n",
    "    def score(self): pass\n",
    "\n",
    "\n",
    "def get_top_n_importances(data, estimator, n=10):\n",
    "    # Recupera a importância do estimador.\n",
    "    importances = estimator.feature_importances_\n",
    "    # Recupera o nome das colunas.\n",
    "    column_names = X_train.columns\n",
    "    # Cria um dataframe com as importâncias.\n",
    "    df_importances = pd.DataFrame({'column': column_names, 'importance': importances})\n",
    "    # Recupera os top n importances.\n",
    "    return df_importances.nlargest(n=n, columns='importance', keep='first')\n",
    "\n",
    "\n",
    "def get_classification_results(y_train, y_train_pred, y_dev, y_dev_pred, y_test, y_test_pred):\n",
    "    # Cria um dataframe com todos o resultado de todas as métricas.\n",
    "    return pd.DataFrame({\n",
    "        'type':['train', 'dev', 'test'],\n",
    "        \n",
    "        'f1': [f1_score(y_train, y_train_pred), \n",
    "               f1_score(y_dev, y_dev_pred), \n",
    "               f1_score(y_test, y_test_pred)],\n",
    "\n",
    "        'precision': [precision_score(y_train, y_train_pred), \n",
    "                      precision_score(y_dev, y_dev_pred), \n",
    "                      precision_score(y_test, y_test_pred)],\n",
    "\n",
    "        'recall': [recall_score(y_train, y_train_pred), \n",
    "                      recall_score(y_dev, y_dev_pred), \n",
    "                      recall_score(y_test, y_test_pred)],\n",
    "\n",
    "        'accuracy': [accuracy_score(y_train, y_train_pred), \n",
    "                     accuracy_score(y_dev, y_dev_pred), \n",
    "                     accuracy_score(y_test, y_test_pred)],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb645f",
   "metadata": {},
   "source": [
    "## Carregando conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c027b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera o arquivo de entrada de treinamento.\n",
    "train_xml_root = et.parse('../data/assin2-train.xml').getroot()\n",
    "# Cria o dataframe de treinamento.\n",
    "df_train = parse_xml_to_df(train_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "dev_xml_root = et.parse('../data/assin2-dev.xml').getroot()\n",
    "# Cria o dataframe de validação.\n",
    "df_dev = parse_xml_to_df(dev_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "test_xml_root = et.parse('../data/assin2-test.xml').getroot()\n",
    "df_test = parse_xml_to_df(test_xml_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e341738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 4)\n",
      "Shape de validação: (500, 4)\n",
      "Shape de teste: (2448, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape de treinamento:', df_train.shape)\n",
    "print('Shape de validação:', df_dev.shape)\n",
    "print('Shape de teste:', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08697b99",
   "metadata": {},
   "source": [
    "## Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f8f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma coluna que concatena as duas frases em uma nas bases de dados.\n",
    "df_train['t_h'] = df_train['t'] + ' ' + df_train['h']  \n",
    "df_dev['t_h'] = df_dev['t'] + ' ' + df_dev['h']  \n",
    "df_test['t_h'] = df_test['t'] + ' ' + df_test['h']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbc9e5",
   "metadata": {},
   "source": [
    "# Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051af4a8",
   "metadata": {},
   "source": [
    "## Abordagem 1: BoW concatenando ambas as frases em uma única frase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d51423-dc51-4096-8e99-f2f354853af1",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42041580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 2310) (6500,)\n",
      "Shape de validação: (500, 2310) (500,)\n",
      "Shape de teste: (2448, 2310) (2448,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instancia um objeto para realizar o bag of words.\n",
    "vectorizer = CountVectorizer()\n",
    "# Ajusta o BoW no conjunto de treinamento.\n",
    "vectorizer.fit(df_train['t_h'])\n",
    "\n",
    "# Vetorizando o conjunto de treinamento.\n",
    "df_train_vec = pd.DataFrame(vectorizer.transform(df_train['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_train_vec['is_entailment'] = df_train['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_dev_vec = pd.DataFrame(vectorizer.transform(df_dev['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_dev_vec['is_entailment'] = df_dev['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_test_vec = pd.DataFrame(vectorizer.transform(df_test['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_test_vec['is_entailment'] = df_test['is_entailment']\n",
    "\n",
    "X_train, y_train = df_train_vec.drop(columns='is_entailment'), df_train_vec['is_entailment'].astype(int)\n",
    "X_dev, y_dev = df_dev_vec.drop(columns='is_entailment'), df_dev_vec['is_entailment'].astype(int)\n",
    "X_test, y_test = df_test_vec.drop(columns='is_entailment'), df_test_vec['is_entailment'].astype(int)\n",
    "\n",
    "print('Shape de treinamento:', X_train.shape, y_train.shape)\n",
    "print('Shape de validação:', X_dev.shape, y_dev.shape)\n",
    "print('Shape de teste:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca84a5-3798-400c-a91a-efc5fc441171",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5721a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>não</td>\n",
       "      <td>0.102028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>tofu</td>\n",
       "      <td>0.010888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>fundo</td>\n",
       "      <td>0.010294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>dele</td>\n",
       "      <td>0.008303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>por</td>\n",
       "      <td>0.007710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>mãos</td>\n",
       "      <td>0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>ninguém</td>\n",
       "      <td>0.006547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>senhora</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>óculos</td>\n",
       "      <td>0.006303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>guardando</td>\n",
       "      <td>0.006234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column  importance\n",
       "1525        não    0.102028\n",
       "2154       tofu    0.010888\n",
       "1086      fundo    0.010294\n",
       "685        dele    0.008303\n",
       "1766        por    0.007710\n",
       "1475       mãos    0.006723\n",
       "1512    ninguém    0.006547\n",
       "2016    senhora    0.006521\n",
       "2307     óculos    0.006303\n",
       "1146  guardando    0.006234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.939864</td>\n",
       "      <td>0.921123</td>\n",
       "      <td>0.959385</td>\n",
       "      <td>0.938615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0.772872</td>\n",
       "      <td>0.680772</td>\n",
       "      <td>0.893791</td>\n",
       "      <td>0.737337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type        f1  precision    recall  accuracy\n",
       "0  train  0.939864   0.921123  0.959385  0.938615\n",
       "1    dev  0.884921   0.877953  0.892000  0.884000\n",
       "2   test  0.772872   0.680772  0.893791  0.737337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cria o pipeline de transformação.\n",
    "pipe = Pipeline([('clf', GenericEstimator())])\n",
    "\n",
    "# Define um espaço de busca com diferentes algoritmos.\n",
    "search_space = [\n",
    "    {'clf': [LogisticRegression()],\n",
    "     'clf__penalty': ['l1', 'l2'],\n",
    "    },\n",
    "    \n",
    "    {'clf': [xgb.XGBClassifier()],\n",
    "     'clf__n_estimators': [150],\n",
    "    'clf__max_depth': [2, 10]},\n",
    "    \n",
    "    {'clf': [RandomForestClassifier()],\n",
    "     'clf__n_estimators': [150, 250],\n",
    "     'clf__max_depth': [2, 10, 20]},\n",
    "\n",
    "]\n",
    "    \n",
    "# Cria um objeto de busca em grid com semente setada para reprodutibilidade.    \n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    search_space, \n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajusta no conjunto de treinamento.\n",
    "grid.fit(X_train, y_train)\n",
    "# Recupera os resultados da validação cruzada.\n",
    "df_first_training_results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "# Recupera os resultados\n",
    "y_train_pred = grid.predict(X_train)\n",
    "y_dev_pred = grid.predict(X_dev)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "# Recuperando as importâncias das features.\n",
    "df_first_approach_importances = get_top_n_importances(X_train, grid.best_estimator_[0])\n",
    "display(first_approach_importances)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "df_first_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(df_first_approach_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98177c-0f9c-4b05-93f8-5c317d73340f",
   "metadata": {},
   "source": [
    "## Abordagem 2: BoW concatenando ambas as frases em uma única frase com PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ed856-7cd6-4f95-976d-efe84b31d982",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba75fe9-eadc-4383-9b04-c636bf3f281d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan 0.16208374 0.16917762 0.17488034 0.19066455 0.28940696\n",
      " 0.33307194 0.37935229 0.27240686 0.28607568 0.29962561 0.32792213\n",
      " 0.39636933 0.41597782 0.43652688 0.44373769 0.4521781  0.46246353\n",
      " 0.46869323 0.49080383 0.50022988 0.49779293 0.1518731  0.13650835\n",
      " 0.15738476 0.14360611 0.15132001 0.14993413 0.1322477  0.14715615\n",
      " 0.13589742 0.15013849 0.15131707 0.14676142 0.15273607 0.13694661\n",
      " 0.27460259 0.28144485 0.31731073 0.3529031  0.40380601 0.41892264\n",
      " 0.42382484 0.27174922 0.28165756 0.31610195 0.34893911 0.40117498\n",
      " 0.41742097 0.42157716 0.44445585 0.44484972 0.45848874 0.46795943\n",
      " 0.48678091 0.48828323 0.48337067 0.44634554 0.44535716 0.46234924\n",
      " 0.46852989 0.48673947 0.48999354 0.48784094]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.949439</td>\n",
       "      <td>0.948419</td>\n",
       "      <td>0.950462</td>\n",
       "      <td>0.949385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0.700511</td>\n",
       "      <td>0.600818</td>\n",
       "      <td>0.839869</td>\n",
       "      <td>0.640931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type        f1  precision    recall  accuracy\n",
       "0  train  0.949439   0.948419  0.950462  0.949385\n",
       "1    dev  0.877551   0.895833  0.860000  0.880000\n",
       "2   test  0.700511   0.600818  0.839869  0.640931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Cria o pipeline de transformação.\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA(random_state=42)),\n",
    "    ('clf', GenericEstimator())\n",
    "])\n",
    "\n",
    "# Define um espaço de busca com diferentes algoritmos.\n",
    "search_space = [\n",
    "    {'clf': [LogisticRegression()],\n",
    "     'clf__penalty': ['l1', 'l2'],\n",
    "     'pca': [PCA(random_state=42)],\n",
    "     'pca__n_components': [2, 3, 4, 5, 10, 20, 100]\n",
    "    },\n",
    "    \n",
    "    {'clf': [xgb.XGBClassifier()],\n",
    "     'clf__n_estimators': [150],\n",
    "     'clf__max_depth': [2, 10],\n",
    "     'pca': [PCA(random_state=42)],\n",
    "     'pca__n_components': [2, 3, 4, 5, 10, 20, 100]\n",
    "    },\n",
    "    \n",
    "    {'clf': [RandomForestClassifier()],\n",
    "     'clf__n_estimators': [150, 250],\n",
    "     'clf__max_depth': [2, 10, 20],\n",
    "     'pca': [PCA(random_state=42)],\n",
    "     'pca__n_components': [2, 3, 4, 5, 10, 20, 100]\n",
    "    },\n",
    "]\n",
    "    \n",
    "# Cria um objeto de busca em grid com semente setada para reprodutibilidade.    \n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    search_space, \n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajusta no conjunto de treinamento.\n",
    "grid.fit(X_train, y_train)\n",
    "# Recupera os resultados da validação cruzada.\n",
    "df_second_training_results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'std_test_score']]\n",
    "# Recupera os resultados\n",
    "y_train_pred = grid.predict(X_train)\n",
    "y_dev_pred = grid.predict(X_dev)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "df_second_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(df_second_approach_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4460d-5e8a-4b1d-907d-4e9ed4ace4ab",
   "metadata": {},
   "source": [
    "# Abordagem 3: TF-IDF concatenando ambas as frases em uma única frase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca172d7-2890-4bc3-a795-df2a69d47f9d",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88acf6c8-9a6f-4ebf-a6f2-f5c41728976e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 2310) (6500,)\n",
      "Shape de validação: (500, 2310) (500,)\n",
      "Shape de teste: (2448, 2310) (2448,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instancia um objeto para realizar o bag of words.\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Ajusta o BoW no conjunto de treinamento.\n",
    "vectorizer.fit(df_train['t_h'])\n",
    "\n",
    "# Vetorizando o conjunto de treinamento.\n",
    "df_train_vec = pd.DataFrame(vectorizer.transform(df_train['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_train_vec['is_entailment'] = df_train['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_dev_vec = pd.DataFrame(vectorizer.transform(df_dev['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_dev_vec['is_entailment'] = df_dev['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_test_vec = pd.DataFrame(vectorizer.transform(df_test['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_test_vec['is_entailment'] = df_test['is_entailment']\n",
    "\n",
    "X_train, y_train = df_train_vec.drop(columns='is_entailment'), df_train_vec['is_entailment'].astype(int)\n",
    "X_dev, y_dev = df_dev_vec.drop(columns='is_entailment'), df_dev_vec['is_entailment'].astype(int)\n",
    "X_test, y_test = df_test_vec.drop(columns='is_entailment'), df_test_vec['is_entailment'].astype(int)\n",
    "\n",
    "print('Shape de treinamento:', X_train.shape, y_train.shape)\n",
    "print('Shape de validação:', X_dev.shape, y_dev.shape)\n",
    "print('Shape de teste:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1037b9e-a6c9-488a-9dc9-c333a96718de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff3e597-3735-45ef-9261-e143db54916b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.42970002 0.46631257 0.50674587 0.1411926  0.14464286\n",
      " 0.21057312 0.2053639  0.35782807 0.35819089]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>não</td>\n",
       "      <td>0.058896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>corajosamente</td>\n",
       "      <td>0.011095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>fundo</td>\n",
       "      <td>0.010216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>passeando</td>\n",
       "      <td>0.009011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>comidas</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>jovens</td>\n",
       "      <td>0.008487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>capa</td>\n",
       "      <td>0.008455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>pouco</td>\n",
       "      <td>0.008015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>ninguém</td>\n",
       "      <td>0.007976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>ovo</td>\n",
       "      <td>0.007768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  importance\n",
       "1525            não    0.058896\n",
       "592   corajosamente    0.011095\n",
       "1086          fundo    0.010216\n",
       "1621      passeando    0.009011\n",
       "548         comidas    0.008843\n",
       "1229         jovens    0.008487\n",
       "406            capa    0.008455\n",
       "1780          pouco    0.008015\n",
       "1512        ninguém    0.007976\n",
       "1571            ovo    0.007768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.933889</td>\n",
       "      <td>0.964923</td>\n",
       "      <td>0.948308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>0.890688</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0.748086</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.878268</td>\n",
       "      <td>0.704248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type        f1  precision    recall  accuracy\n",
       "0  train  0.949153   0.933889  0.964923  0.948308\n",
       "1    dev  0.890688   0.901639  0.880000  0.892000\n",
       "2   test  0.748086   0.651515  0.878268  0.704248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cria o pipeline de transformação.\n",
    "pipe = Pipeline([('clf', GenericEstimator())])\n",
    "\n",
    "# Define um espaço de busca com diferentes algoritmos.\n",
    "search_space = [\n",
    "    {'clf': [LogisticRegression()],\n",
    "     'clf__penalty': ['l1', 'l2'],\n",
    "    },\n",
    "    \n",
    "    {'clf': [xgb.XGBClassifier()],\n",
    "     'clf__n_estimators': [150],\n",
    "    'clf__max_depth': [2, 10]},\n",
    "    \n",
    "    {'clf': [RandomForestClassifier()],\n",
    "     'clf__n_estimators': [150, 250],\n",
    "     'clf__max_depth': [2, 10, 20]},\n",
    "\n",
    "]\n",
    "    \n",
    "# Cria um objeto de busca em grid com semente setada para reprodutibilidade.    \n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    search_space, \n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajusta no conjunto de treinamento.\n",
    "grid.fit(X_train, y_train)\n",
    "# Recupera os resultados da validação cruzada.\n",
    "df_third_training_results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "# Recupera os resultados\n",
    "y_train_pred = grid.predict(X_train)\n",
    "y_dev_pred = grid.predict(X_dev)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "# Recuperando as importâncias das features.\n",
    "df_third_approach_importances = get_top_n_importances(X_train, grid.best_estimator_[0])\n",
    "display(df_third_approach_importances)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "df_third_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(df_third_approach_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc4747-d7f4-427a-8973-08a981409050",
   "metadata": {},
   "source": [
    "## Abordagem 4: BoW concatenando ambas as frases em uma única frase e n-grams=(1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed034f3f-f539-4024-895f-1913d46e3ec8",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4646ff29-3048-436d-909e-3ae70489da41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 33527) (6500,)\n",
      "Shape de validação: (500, 33527) (500,)\n",
      "Shape de teste: (2448, 33527) (2448,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instancia um objeto para realizar o bag of words com unigramas até trigramas.\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "# Ajusta o BoW no conjunto de treinamento.\n",
    "vectorizer.fit(df_train['t_h'])\n",
    "\n",
    "# Vetorizando o conjunto de treinamento.\n",
    "df_train_vec = pd.DataFrame(vectorizer.transform(df_train['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_train_vec['is_entailment'] = df_train['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_dev_vec = pd.DataFrame(vectorizer.transform(df_dev['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_dev_vec['is_entailment'] = df_dev['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_test_vec = pd.DataFrame(vectorizer.transform(df_test['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_test_vec['is_entailment'] = df_test['is_entailment']\n",
    "\n",
    "X_train, y_train = df_train_vec.drop(columns='is_entailment'), df_train_vec['is_entailment'].astype(int)\n",
    "X_dev, y_dev = df_dev_vec.drop(columns='is_entailment'), df_dev_vec['is_entailment'].astype(int)\n",
    "X_test, y_test = df_test_vec.drop(columns='is_entailment'), df_test_vec['is_entailment'].astype(int)\n",
    "\n",
    "print('Shape de treinamento:', X_train.shape, y_train.shape)\n",
    "print('Shape de validação:', X_dev.shape, y_dev.shape)\n",
    "print('Shape de teste:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762a125-732f-42b2-b196-39c0c28b886f",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c35abc-1d48-49df-ad9b-ac91d4c2956d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/vfsilva/virtualenvs/phd-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cria o pipeline de transformação.\n",
    "pipe = Pipeline([('clf', GenericEstimator())])\n",
    "\n",
    "# Define um espaço de busca com diferentes algoritmos.\n",
    "search_space = [\n",
    "    {'clf': [LogisticRegression()],\n",
    "     'clf__penalty': ['l1', 'l2'],\n",
    "    },\n",
    "    \n",
    "    {'clf': [xgb.XGBClassifier()],\n",
    "     'clf__n_estimators': [150],\n",
    "    'clf__max_depth': [2, 10]},\n",
    "    \n",
    "    {'clf': [RandomForestClassifier()],\n",
    "     'clf__n_estimators': [150, 250],\n",
    "     'clf__max_depth': [2, 10, 20]},\n",
    "\n",
    "]\n",
    "    \n",
    "# Cria um objeto de busca em grid com semente setada para reprodutibilidade.    \n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    search_space, \n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajusta no conjunto de treinamento.\n",
    "grid.fit(X_train, y_train)\n",
    "# Recupera os resultados da validação cruzada.\n",
    "df_fourth_training_results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "# Recupera os resultados\n",
    "y_train_pred = grid.predict(X_train)\n",
    "y_dev_pred = grid.predict(X_dev)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "# Recuperando as importâncias das features.\n",
    "df_fourth_approach_importances = get_top_n_importances(X_train, grid.best_estimator_[0])\n",
    "display(df_fourth_approach_importances)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "df_fourth_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(df_fourth_approach_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dda655-57a0-4bf9-8141-46965df36469",
   "metadata": {},
   "source": [
    "# Comparação entre abordagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbff42-4af8-4d85-9df4-84571518e9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
