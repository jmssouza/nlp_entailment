{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8341afac",
   "metadata": {},
   "source": [
    "# Inicialização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be223a",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas e funções de auxílio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3985c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "\n",
    "def parse_xml_to_df(xml_root):\n",
    "    # Cria um dataframe vazio em que as linhas serão concatenadas.\n",
    "    df = pd.DataFrame(columns=['similarity', 't', 'h'])\n",
    "    # Para cada par na root.\n",
    "    for pair in xml_root:\n",
    "        # Recupera o valor de t.\n",
    "        t = pair[0].text\n",
    "        # Recupera o valor de h.\n",
    "        h = pair[1].text\n",
    "        # Recupera o valor da variável target.\n",
    "        is_entailment = pair.attrib['entailment'] == 'Entailment'\n",
    "        # Recupera o valor de similaridade atribuído.\n",
    "        similarity = float(pair.attrib['similarity'])\n",
    "        # Constroi a nova linha.\n",
    "        new_line = pd.DataFrame([{'t': t, 'h': h, 'similarity': similarity, 'is_entailment': is_entailment}])\n",
    "        # Adiciona ao dataframe.\n",
    "        df = pd.concat([df, new_line], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "    \n",
    "class GenericEstimator(BaseEstimator):\n",
    "    # Classificador genérico para usar o gridsearch com múltiplos algoritmos.\n",
    "    def fit(self): pass\n",
    "    \n",
    "    def score(self): pass\n",
    "\n",
    "\n",
    "def get_top_n_importances(data, estimator, n=10):\n",
    "    # Recupera a importância do estimador.\n",
    "    importances = estimator.feature_importances_\n",
    "    # Recupera o nome das colunas.\n",
    "    column_names = X_train.columns\n",
    "    # Cria um dataframe com as importâncias.\n",
    "    df_importances = pd.DataFrame({'column': column_names, 'importance': importances})\n",
    "    # Recupera os top n importances.\n",
    "    return df_importances.nlargest(n=n, columns='importance', keep='first')\n",
    "\n",
    "\n",
    "def get_classification_results(y_train, y_train_pred, y_dev, y_dev_pred, y_test, y_test_pred):\n",
    "    # Cria um dataframe com todos o resultado de todas as métricas.\n",
    "    return pd.DataFrame({\n",
    "        'type':['train', 'dev', 'test'],\n",
    "        \n",
    "        'f1': [f1_score(y_train, y_train_pred), \n",
    "               f1_score(y_dev, y_dev_pred), \n",
    "               f1_score(y_test, y_test_pred)],\n",
    "\n",
    "        'precision': [precision_score(y_train, y_train_pred), \n",
    "                      precision_score(y_dev, y_dev_pred), \n",
    "                      precision_score(y_test, y_test_pred)],\n",
    "\n",
    "        'recall': [recall_score(y_train, y_train_pred), \n",
    "                      recall_score(y_dev, y_dev_pred), \n",
    "                      recall_score(y_test, y_test_pred)],\n",
    "\n",
    "        'accuracy': [accuracy_score(y_train, y_train_pred), \n",
    "                     accuracy_score(y_dev, y_dev_pred), \n",
    "                     accuracy_score(y_test, y_test_pred)],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb645f",
   "metadata": {},
   "source": [
    "## Carregando conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c027b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera o arquivo de entrada de treinamento.\n",
    "train_xml_root = et.parse('../data/assin2-train.xml').getroot()\n",
    "# Cria o dataframe de treinamento.\n",
    "df_train = parse_xml_to_df(train_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "dev_xml_root = et.parse('../data/assin2-dev.xml').getroot()\n",
    "# Cria o dataframe de validação.\n",
    "df_dev = parse_xml_to_df(dev_xml_root)\n",
    "\n",
    "# Recupera o arquivo de entrada de validação.\n",
    "test_xml_root = et.parse('../data/assin2-test.xml').getroot()\n",
    "df_test = parse_xml_to_df(test_xml_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e341738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 4)\n",
      "Shape de validação: (500, 4)\n",
      "Shape de teste: (2448, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape de treinamento:', df_train.shape)\n",
    "print('Shape de validação:', df_dev.shape)\n",
    "print('Shape de teste:', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08697b99",
   "metadata": {},
   "source": [
    "## Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f8f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma coluna que concatena as duas frases em uma nas bases de dados.\n",
    "df_train['t_h'] = df_train['t'] + ' ' + df_train['h']  \n",
    "df_dev['t_h'] = df_dev['t'] + ' ' + df_dev['h']  \n",
    "df_test['t_h'] = df_test['t'] + ' ' + df_test['h']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbc9e5",
   "metadata": {},
   "source": [
    "# Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051af4a8",
   "metadata": {},
   "source": [
    "## Abordagem 1: BoW concatenando ambas as frases em uma única frase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d51423-dc51-4096-8e99-f2f354853af1",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42041580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de treinamento: (6500, 2310) (6500,)\n",
      "Shape de validação: (500, 2310) (500,)\n",
      "Shape de teste: (2448, 2310) (2448,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instancia um objeto para realizar o bag of words.\n",
    "vectorizer = CountVectorizer()\n",
    "# Ajusta o BoW no conjunto de treinamento.\n",
    "vectorizer.fit(df_train['t_h'])\n",
    "\n",
    "# Vetorizando o conjunto de treinamento.\n",
    "df_train_vec = pd.DataFrame(vectorizer.transform(df_train['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_train_vec['is_entailment'] = df_train['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_dev_vec = pd.DataFrame(vectorizer.transform(df_dev['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_dev_vec['is_entailment'] = df_dev['is_entailment']\n",
    "\n",
    "# Vetorizando o conjunto de validação.\n",
    "df_test_vec = pd.DataFrame(vectorizer.transform(df_test['t_h']).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_test_vec['is_entailment'] = df_test['is_entailment']\n",
    "\n",
    "X_train, y_train = df_train_vec.drop(columns='is_entailment'), df_train_vec['is_entailment'].astype(int)\n",
    "X_dev, y_dev = df_dev_vec.drop(columns='is_entailment'), df_dev_vec['is_entailment'].astype(int)\n",
    "X_test, y_test = df_test_vec.drop(columns='is_entailment'), df_test_vec['is_entailment'].astype(int)\n",
    "\n",
    "print('Shape de treinamento:', X_train.shape, y_train.shape)\n",
    "print('Shape de validação:', X_dev.shape, y_dev.shape)\n",
    "print('Shape de teste:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca84a5-3798-400c-a91a-efc5fc441171",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5721a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>não</td>\n",
       "      <td>0.102028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>tofu</td>\n",
       "      <td>0.010888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>fundo</td>\n",
       "      <td>0.010294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>dele</td>\n",
       "      <td>0.008303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>por</td>\n",
       "      <td>0.007710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>mãos</td>\n",
       "      <td>0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>ninguém</td>\n",
       "      <td>0.006547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>senhora</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>óculos</td>\n",
       "      <td>0.006303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>guardando</td>\n",
       "      <td>0.006234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column  importance\n",
       "1525        não    0.102028\n",
       "2154       tofu    0.010888\n",
       "1086      fundo    0.010294\n",
       "685        dele    0.008303\n",
       "1766        por    0.007710\n",
       "1475       mãos    0.006723\n",
       "1512    ninguém    0.006547\n",
       "2016    senhora    0.006521\n",
       "2307     óculos    0.006303\n",
       "1146  guardando    0.006234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.939864</td>\n",
       "      <td>0.921123</td>\n",
       "      <td>0.959385</td>\n",
       "      <td>0.938615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0.772872</td>\n",
       "      <td>0.680772</td>\n",
       "      <td>0.893791</td>\n",
       "      <td>0.737337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type        f1  precision    recall  accuracy\n",
       "0  train  0.939864   0.921123  0.959385  0.938615\n",
       "1    dev  0.884921   0.877953  0.892000  0.884000\n",
       "2   test  0.772872   0.680772  0.893791  0.737337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cria o pipeline de transformação.\n",
    "pipe = Pipeline([('clf', GenericEstimator())])\n",
    "\n",
    "# Define um espaço de busca com diferentes algoritmos.\n",
    "search_space = [\n",
    "    {'clf': [xgb.XGBClassifier()],\n",
    "     'clf__n_estimators': [150],\n",
    "    'clf__max_depth': [2, 10]},\n",
    "    \n",
    "    {'clf': [RandomForestClassifier()],\n",
    "     'clf__n_estimators': [150, 250],\n",
    "     'clf__max_depth': [2, 10, 20]},\n",
    "\n",
    "]\n",
    "    \n",
    "# Cria um objeto de busca em grid com semente setada para reprodutibilidade.    \n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    search_space, \n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Ajusta no conjunto de treinamento.\n",
    "grid.fit(X_train, y_train)\n",
    "# Recupera os resultados da validação cruzada.\n",
    "df_training_results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'std_test_score']]\n",
    "# Recupera os resultados\n",
    "y_train_pred = grid.predict(X_train)\n",
    "y_dev_pred = grid.predict(X_dev)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "# Recuperando as importâncias das features.\n",
    "first_approach_importances = get_top_n_importances(X_train, grid.best_estimator_[0])\n",
    "display(first_approach_importances)\n",
    "\n",
    "# Calcula as métricas de performance dos resultados do modelo.\n",
    "first_approach_results = get_classification_results(\n",
    "    y_train, \n",
    "    y_train_pred, \n",
    "    y_dev, \n",
    "    y_dev_pred, \n",
    "    y_test, \n",
    "    y_test_pred)\n",
    "display(first_approach_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b329c-fa03-4552-bc45-f87f261d978a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
